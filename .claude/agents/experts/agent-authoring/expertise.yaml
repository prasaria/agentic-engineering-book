# Agent Authoring & Configuration Expertise
# Target: 500-750 lines | Domain: Operational knowledge for agent creation

overview:
  description: |
    Agent authoring and configuration—agent frontmatter schema, tool selection
    rules by role, description writing patterns, model selection decision tree,
    and system prompt structure. This expertise enables correct agent configuration
    for discoverability, capability, and appropriate model selection.
  scope: |
    Covers agent.md frontmatter (name, description, tools, model, color),
    tool selection patterns by agent role, description conventions, model
    selection for agents, and system prompt organization. Does NOT cover
    prompt content specifics (see prompt chapter) or orchestration patterns
    (see orchestration expert).
  rationale: |
    Consistent agent configuration enables discoverability, correct tool usage,
    and appropriate model selection. Poor agent config leads to capability gaps,
    security issues, and confusion about agent responsibilities.

core_implementation:
  primary_files:
    - path: .claude/agents/
      purpose: All agent examples with frontmatter patterns
    - path: .claude/agents/experts/
      purpose: Expert domain patterns (4-agent standard: plan/build/improve/question)
    - path: .claude/skills/
      purpose: Workflow templates (not agents) - guides /do orchestration
    - path: .claude/commands/do.md
      purpose: Universal orchestrator - directly spawns expert agents (flat architecture)

  key_sections:
    - name: Agent Frontmatter
      location: .claude/agents/scout-agent.md (lines 1-7)
      summary: Complete frontmatter example with all fields
    - name: Expert Build Agent
      location: .claude/agents/experts/knowledge/knowledge-build-agent.md
      summary: Worker pattern with Write, no Task

key_operations:
  write_agent_frontmatter:
    name: Write Complete Agent Frontmatter
    description: Populate all agent.md frontmatter fields correctly
    when_to_use: Creating new agent or updating existing
    approach: |
      Required frontmatter fields:
      1. name: kebab-case identifier (e.g., knowledge-plan-agent)
      2. description: Action verb + trigger + context (see description patterns)
      3. tools: Comma-separated list based on role (see tool selection)
      4. model: haiku/sonnet/opus (see model selection)

      Optional frontmatter fields:
      5. color: Visual identifier with semantic meaning (see color_semantics)
      6. output-style: References .claude/output-styles/{value}.md
         - question agents: concise-reference (100% consistency across 11 agents)
         - plan agents: academic-structured OR practitioner-focused (domain-dependent)
         - build agents: practitioner-focused (92% consistency, questions domain uses narrative-technical)
         - improve agents: evidence-grounded OR practitioner-focused (domain-dependent)
      7. temperature: Override if needed (default 1.0)
      8. timescale: inference | session | cross_session (learning architecture)
      9. learning_inputs/outputs: {timescale}: {source/destination} (knowledge flow)

      *[2025-12-28]* Output-style field pattern:
      - Add frontmatter field: output-style: {style-name}
      - Reference in Instructions: "Follow .claude/output-styles/{style}.md conventions"
      - Include 2-3 key style reminders inline (fragments, tables, bullets)
      - Do NOT read full style file into prompt (too heavy for context)

      Style selection is domain-sensitive:
      - Operational domains (github, do-management, orchestration, external-teacher): practitioner-focused for ALL phases
      - Research/content domains (knowledge, research): evidence-grounded for improve, academic-structured for plan
      - Configuration domains (claude-config, curriculum): practitioner-focused throughout
      - Questions domain: narrative-technical for ASK/BUILD/DEEPEN (conversational), practitioner-focused for FORMAT/IMPROVE

      Color semantics (from meta-agent):
      - blue: Read-only exploration, research
      - green: Building, creating content, versioning
      - yellow: Analysis, planning, maintenance
      - orange: Coordination, orchestration
      - red: Deletion, cleanup, risky operations
      - purple: Review, evaluation, research coordination
      - cyan: Meta operations
      - pink: Specialized utilities

      *[2025-12-26]* Standard color scheme for 4-agent expert pattern:
      - Plan agents: yellow (analysis)
      - Build agents: green (creation)
      - Improve agents: purple (learning)
      - Question agents: cyan (advisory)

      Format:
      ---
      name: agent-name
      description: Brief action-oriented description
      tools: Read, Glob, Grep
      model: sonnet
      color: green
      ---
    examples:
      - agent: scout-agent
        frontmatter: "name: scout-agent | description: Use proactively for read-only exploration | tools: Read, Glob, Grep | model: haiku"
      - agent: knowledge-build-agent
        frontmatter: "name: knowledge-build-agent | description: Implement book content updates from approved specifications | tools: Read, Write, Edit, Grep, Glob | model: sonnet"
    pitfalls:
      - what: Generic descriptions like "Helper agent"
        instead: Action verb + specific trigger + context
      - what: Missing tools field
        instead: Always explicitly declare needed tools
      - what: "CRITICAL - Using colons in description field (e.g., 'Expects: SPEC')"
        instead: "Remove colons from description values (use 'Expects SPEC' not 'Expects: SPEC')"
        reason: "Colons in YAML string values cause Claude Code's agent discovery parser to fail silently. Agents with colons in descriptions will NOT appear in /agents list or agent selection UIs. [2026-01-17] Root cause confirmed via commit b6a2b47 which fixed 38 agent descriptions across all expert domains. Pattern affected 100% of plan/build/improve/question agents."
        evidence: "Commit b6a2b47 (2026-01-17): Fixed 38 agents across 12 expert domains. Before: 'Expects: USER_PROMPT' pattern in every agent description. After: 'Expects USER_PROMPT' (no colon). Systematic fix applied to agent-authoring, audit, book-structure, claude-config, do-management, external-teacher, github, knowledge, orchestration, questions domain agents."

  select_tools_by_role:
    name: Select Tools Based on Agent Role
    description: Grant appropriate tools for agent's function
    when_to_use: Configuring tools field in frontmatter
    approach: |
      Read-Only (Exploration/Analysis):
      - Read, Glob, Grep
      - Optional: Bash (read-only commands only)
      - NO Write, Edit, Task

      Content Updates (Workers/Builders):
      - Read, Write, Edit, Grep, Glob
      - Optional: Bash (for implementation tasks)
      - NO Task (workers don't spawn others)

      Coordination (Orchestrators):
      - Task, Read, Grep, Glob
      - Optional: TodoWrite, AskUserQuestion, Bash
      - Write permitted for complex orchestrators only
    examples:
      - role: Scout/Explorer
        tools: Read, Glob, Grep
      - role: Knowledge Build Agent
        tools: Read, Write, Edit, Grep, Glob
      - role: Audit Orchestrator
        tools: Task, Read, Write, Glob, Grep, Bash
    pitfalls:
      - what: Giving all agents all tools
        instead: Minimal tool set for role
      - what: Simple coordinators with Write access
        instead: Only complex orchestrators generate reports

  select_model_for_agent:
    name: Select Model for Agent
    description: Choose appropriate model based on reasoning needs and cost
    when_to_use: Setting model field in frontmatter
    approach: |
      Model selection decision tree:

      haiku (fast, cheap):
      - Simple structured output generation
      - Routing and classification tasks
      - Read-only exploration (scout agents)
      - Test first before downgrading from sonnet

      sonnet (balanced, default):
      - Default for most agents
      - Planning and analysis tasks
      - Content creation and implementation

      opus (powerful, expensive):
      - Complex multi-step reasoning
      - Orchestration and coordination decisions
      - Meta-agent operations
    examples:
      - agent: scout-agent | model: haiku | reason: Fast exploration
      - agent: knowledge-plan-agent | model: sonnet | reason: Moderate planning
      - agent: meta-agent | model: opus | reason: Complex generation

  write_agent_description:
    name: Write Effective Agent Description
    description: Create description that aids discoverability and invocation
    when_to_use: Writing description field in frontmatter
    approach: |
      Pattern: [Action Verb] + [Domain/Object] + [Trigger/Context]

      Components:
      1. Action verb: Analyze, Plan, Build, Review, Explore, Generate
      2. Domain/Object: What it acts on
      3. Trigger/Context: When/why to invoke (optional but valuable)

      Character limit: Keep under 100 characters if possible
      Proactive trigger: "Use proactively for..." signals auto-delegation

      Description patterns by role:
      - Scout: "Use proactively for read-only exploration of..."
      - Planner: "Plan [domain] updates by analyzing requirements and..."
      - Builder: "Implement [domain] from approved specifications"
      - Coordinator: "Orchestrates [workflow] via [pattern] cycle"
    examples:
      - good: "Use proactively for read-only exploration of the agentic engineering book"
      - bad: "Helper for knowledge tasks" (vague, no action verb)

  structure_agent_prompt:
    name: Structure Agent System Prompt Content
    description: Organize agent prompt with clear sections
    when_to_use: Writing agent body content (after frontmatter)
    approach: |
      Standard sections (in order):
      1. # Purpose - What the agent does and why (1-2 paragraphs)
      2. ## Variables - Expected inputs (USER_PROMPT, PATH_TO_SPEC, etc.)
      3. ## Instructions - Key constraints, tool usage, voice/approach
      4. ## Expertise (optional) - Domain knowledge, updated by improve agents
      5. ## Workflow - Numbered steps, stable, clear phase boundaries
      6. ## Report - Output format template

      Note: Expertise sections are mutable (updated by improve agents)
      Note: Workflow sections are stable (rarely changed)
    examples:
      - location: .claude/agents/scout-agent.md
        sections: Purpose, Critical Constraints, Instructions, Report Format
      - location: .claude/agents/experts/knowledge/knowledge-plan-agent.md
        sections: Purpose, Variables, Instructions, Expertise, Workflow, Report

  migrate_safety_protocols_to_expert:
    name: Migrate Safety Protocols from Standalone to Expert Domain
    description: Extract inline safety constraints to structured expertise.yaml
    when_to_use: Converting standalone agent with safety constraints to expert domain
    approach: |
      Extract inline safety constraints to expertise.yaml safety_protocols section:

      expertise.yaml pattern:
      ```yaml
      safety_protocols:
        - protocol: Never Force Push
          description: Do not use `git push --force` without explicit user request
          rationale: Rewrites history, breaks collaborators' local repos
          exception: User explicitly requests it for known reason
          timestamp: 2025-12-26
      ```

      Build agent enforcement:
      - Include NEVER/ALWAYS constraints in Instructions
      - Pre-execution safety checks in Workflow

      Distribution:
      - expertise.yaml: Authoritative source with rationale/exception
      - Build agent: Enforces via pre-execution checks
      - Question agent: Surfaces in FAQ-style responses
    examples:
      - domain: github
        protocols_migrated: 5 (Never Force Push, Never Amend Pushed Commits, etc.)
        location: .claude/agents/experts/github/expertise.yaml

decision_trees:
  tool_selection_by_role:
    name: Tool Selection Decision Tree
    entry_point: What is agent's primary function?
    branches:
      - condition: Read-only exploration/analysis
        action: Read, Glob, Grep (no Write, no Task)
      - condition: Content creation/implementation
        action: Read, Write, Edit, Grep, Glob (no Task)
      - condition: Workflow coordination/orchestration
        action: Task, Read, Grep, Glob, AskUserQuestion (no Write)
      - condition: Meta-operations (agent generation)
        action: All tools (document justification)

  model_selection_by_complexity:
    name: Model Selection for Agent
    entry_point: What level of reasoning is required?
    branches:
      - condition: Simple structured output, routing, classification
        action: haiku (test first to verify)
      - condition: Moderate planning, analysis, implementation
        action: sonnet (default for most agents)
      - condition: Complex orchestration, multi-step reasoning
        action: opus (justified by complexity)

  description_pattern_selection:
    name: Description Pattern by Role
    entry_point: What role does this agent serve?
    branches:
      - condition: Exploration/scouting
        action: "Use proactively for read-only exploration of..."
      - condition: Planning/analysis
        action: "Plan [domain] by analyzing [inputs]"
      - condition: Building/implementation
        action: "Implement [domain] from [source]"
      - condition: Coordination/orchestration
        action: "Orchestrates [workflow] via [pattern]"

  output_style_selection_by_domain:
    name: Output-Style Selection Decision Tree
    entry_point: What is the domain's primary purpose?
    branches:
      - condition: Operational domain (github, deployment, do-management, orchestration, external-teacher)
        action: "practitioner-focused for ALL phases (plan/build/improve)"
        rationale: "Hands-on execution focus, immediate actionability"
      - condition: Content/research domain (knowledge, research, audit, book-structure, agent-authoring)
        action: "academic-structured for plan, evidence-grounded for improve, practitioner-focused for build"
        rationale: "Structured analysis in planning, evidence-based learning in improvement"
      - condition: Configuration domain (claude-config, curriculum)
        action: "practitioner-focused for ALL phases"
        rationale: "Technical configuration requires practical, hands-on approach"
      - condition: Conversational workflow (questions ASK/BUILD/DEEPEN)
        action: "narrative-technical (storytelling with precision)"
        rationale: "User-facing interaction benefits from conversational tone"
      - condition: Question agent (any domain)
        action: "concise-reference (always)"
        rationale: "Fast lookup, fragment-friendly, table-heavy answers"

patterns:
  expert_4agent_pattern:
    name: Expert 4-Agent Pattern (Standard)
    context: Domain experts with plan/build/improve/question workflow
    implementation: |
      Standard 4-Agent Pattern:
      .claude/agents/experts/<domain>/
      ├── expertise.yaml                   # 450-750 line structured knowledge
      ├── <domain>-plan-agent.md          # Analyzes requirements, writes spec
      ├── <domain>-build-agent.md         # Implements from spec
      ├── <domain>-improve-agent.md       # Updates expertise from git changes
      └── <domain>-question-agent.md      # Read-only Q&A about domain

      Tool sets by agent role:
      - Plan: Read, Glob, Grep, Write (Write for spec caching)
      - Build: Read, Write, Edit, Glob, Grep (no Task)
      - Improve: Read, Write, Edit, Glob, Grep, Bash (Bash for git analysis)
      - Question: Read, Glob, Grep (read-only, advisory)

      Model selection:
      - Plan/Build/Improve: sonnet (default)
      - Question: haiku (fast Q&A)
    trade_offs:
      - advantage: Clear phase separation, parallel-ready
        cost: Multiple agent files per domain
      - advantage: Expertise evolves independently via improve agent
        cost: Must keep agents synchronized
    real_examples:
      - location: .claude/agents/experts/knowledge/
        note: Standard 4-agent pattern with ~750-line expertise.yaml
      - location: .claude/agents/experts/agent-authoring/
        note: Standard 4-agent pattern (this domain)

  read_only_agent_pattern:
    name: Read-Only Agent Pattern
    context: Exploration without modification capability
    implementation: |
      Frontmatter:
      - tools: Read, Glob, Grep (only)
      - model: haiku (fast exploration)
      - color: green or blue (exploration indicator)

      System prompt elements:
      1. Critical Constraints section with ALL-CAPS restrictions
      2. "NEVER use Write, Edit, or Bash tools"
      3. "You are a pure observer and analyst"
      4. Report format that synthesizes findings
    real_examples:
      - location: .claude/agents/scout-agent.md
        note: Complete read-only pattern with constraint emphasis

  question_agent_pattern:
    name: Question Agent Pattern
    context: Read-only Q&A agents that reference expertise.yaml
    implementation: |
      Frontmatter:
      - name: <domain>-question-agent
      - description: "Answers [domain] questions. Expects: USER_PROMPT (required question)"
      - tools: Read, Glob, Grep (read-only, no modification)
      - model: haiku (fast, cheap Q&A)

      System prompt structure:
      1. Purpose: Domain expertise advisor
      2. Variables: USER_PROMPT (required)
      3. Instructions: Read expertise, answer without implementing
      4. Expertise: Quick reference patterns + common question topics
      5. Workflow: Receive → Load → Formulate → Report
      6. Response Format: Answer/Details/Example/Reference structure

      Critical constraints:
      - NEVER use Write, Edit, or other modification tools
      - Pure advisor - returns guidance to caller
      - References expertise.yaml as authoritative source
    real_examples:
      - location: .claude/agents/experts/knowledge/knowledge-question-agent.md
        note: 157 lines, haiku, FAQ structure for knowledge patterns

  absorb_standalone_into_expert_pattern:
    name: Absorb Standalone Agent into Expert Domain Pattern
    context: Converting existing standalone agent into 4-agent expert domain structure
    implementation: |
      When standalone agent contains sufficient domain knowledge, convert to 4-agent pattern.

      Conversion workflow:
      1. Create expert directory: .claude/agents/experts/<domain>/
      2. Extract domain knowledge → expertise.yaml (450-750 lines)
      3. Migrate safety protocols → expertise.yaml safety_protocols section
      4. Create plan/build/improve/question agents (standard 4-agent pattern)
      5. Archive or remove original standalone agent

      Knowledge extraction pattern:
      - Standalone has inline workflow documentation
      - Extract to expertise.yaml key_operations with when_to_use/approach/examples
      - Extract patterns to expertise.yaml patterns section
      - Migrate decision logic to expertise.yaml decision_trees
      - Convert workflow sequences to plan/build agent coordination
    trade_offs:
      - advantage: Structured expertise can evolve independently via improve agent
        cost: More files to maintain (4 agents vs 1)
      - advantage: Plan/build separation enables approval gates
        cost: Additional coordination overhead
    real_examples:
      - location: .claude/agents/experts/github/
        note: Absorbed from github-versioning-agent.md (commit 35a871a). 443-line expertise.yaml

  dual_file_ownership_pattern:
    name: Dual-File Ownership Pattern
    context: Expert domain responsible for multiple tightly-coupled user-facing files
    implementation: |
      *[2025-12-27]*: When files are tightly coupled (changes to one require changes to the other),
      single expert domain owns both files.

      Pattern:
      1. **Single Expert Domain Ownership** - Both files managed by same expert domain
      2. **Build Agent Coordination** - Update both files atomically when changes affect coupling
      3. **Plan Agent Analysis** - Specify which files affected: "FILE_A | FILE_B | Both"
      4. **Improve Agent Learning** - Track changes to both files together

      expertise.yaml pattern:
      ```yaml
      core_implementation:
        primary_files:
          - path: FILE_A.md
            purpose: Primary responsibility
          - path: FILE_B.md
            purpose: Related responsibility
        coupling_points:
          - type: Shared references
          - type: Coordinated updates
      ```
    trade_offs:
      - advantage: Single source of truth for coupled file management
        cost: Build agent more complex (multiple file coordination)
      - advantage: Prevents drift between tightly coupled files
        cost: Both files must be analyzed together (slower planning)
    real_examples:
      - location: .claude/agents/experts/curriculum/
        note: First dual-file domain. CURRICULUM.md (learning paths) + RUBRIC.md (competency assessment)
    timestamp: 2025-12-27

  output_style_field_pattern:
    name: Output-Style Frontmatter Field Pattern
    context: Standardize agent output formatting via output-style frontmatter field referencing .claude/output-styles/ files
    implementation: |
      *[2025-12-28]*: Added output-style field to 55 agent files (all expert domain agents + questions workflow agents).

      Frontmatter addition:
      ```yaml
      ---
      name: agent-name
      output-style: {style-name}
      ---
      ```

      Instructions section reference pattern:
      ```markdown
      **Output Style:** Follow `.claude/output-styles/{style}.md` conventions
      - [Key reminder 1 - e.g., "Use tables for decision frameworks"]
      - [Key reminder 2 - e.g., "Bullets for tool selection lists"]
      - [Key reminder 3 - e.g., "Fragments acceptable"]
      ```

      Phase-to-style mapping (baseline):
      - question → concise-reference (100% adoption, 11/11 agents)
      - plan → academic-structured (36% adoption, 4/11) OR practitioner-focused (64%, 7/11)
      - build → practitioner-focused (92% adoption, 11/12) OR narrative-technical (8%, 1/12)
      - improve → evidence-grounded (33% adoption, 4/12) OR practitioner-focused (67%, 8/12)

      Domain-sensitive style selection observed:
      - **Operational domains** (github, do-management, orchestration, external-teacher):
        practitioner-focused for plan AND improve (consistent throughout)
      - **Content/research domains** (knowledge, research, audit, book-structure, agent-authoring):
        academic-structured for plan, evidence-grounded for improve
      - **Configuration domains** (claude-config, curriculum):
        practitioner-focused throughout (hands-on operational focus)
      - **Questions workflow**: narrative-technical for ASK/BUILD/DEEPEN (conversational),
        practitioner-focused for FORMAT/IMPROVE (operational)

      Key insight: Style selection correlates with domain purpose, not just agent phase.
    trade_offs:
      - advantage: Explicit style guidance prevents output format drift
        cost: Additional frontmatter field to maintain
      - advantage: Reference pattern (not inline docs) keeps prompts lean
        cost: Agent must follow conventions without seeing full style file
      - advantage: Domain-sensitive selection matches agent context
        cost: No single universal mapping, requires domain understanding
    real_examples:
      - location: .claude/agents/experts/agent-authoring/agent-authoring-question-agent.md
        note: "output-style: concise-reference with inline reminder: fragments acceptable"
      - location: .claude/agents/experts/github/github-plan-agent.md
        note: "output-style: practitioner-focused (operational domain, not academic)"
      - location: .claude/agents/experts/questions/questions-ask-agent.md
        note: "output-style: narrative-technical (conversational user interaction)"
    timestamp: 2025-12-28

  coordinator_to_skill_conversion_pattern:
    name: Coordinator-to-Skill Conversion Pattern
    context: Converting coordinator agents to skills due to nested subagent limitations
    implementation: |
      *[2025-12-26]*: Commit 353d576 addressed nested subagent limitation.
      Solution: convert coordinators to skills (workflow templates) and have /do directly orchestrate experts.

      Architecture evolution:
      OLD: /do → coordinator-agent (Task) → expert-agent (nested, broken)
      NEW: /do → expert-agent (flat, works)

      Conversion workflow:
      1. Extract coordinator workflow to .claude/skills/<domain>/SKILL.md
      2. Remove Task orchestration code (now in /do directly)
      3. Keep workflow documentation as template for /do to follow
      4. Delete original coordinator agent file

      Skills are workflow templates, not executable agents:
      - No frontmatter with tools/model (not agents)
      - Pure documentation/guidance for orchestrator
      - Loaded automatically when user request matches triggers

      /do directly orchestrates expert agents (flat architecture):
      - Plan phase → Task(subagent_type: "<domain>-plan-agent")
      - Approval gate → AskUserQuestion at /do level
      - Build phase → Task(subagent_type: "<domain>-build-agent")
      - Improve phase → Task(subagent_type: "<domain>-improve-agent")
    trade_offs:
      - advantage: Eliminates nested subagent limitation (major unlock)
        cost: Centralizes orchestration logic in /do
      - advantage: Skills are pure documentation (easier to maintain)
        cost: No programmatic enforcement of workflow
    real_examples:
      - location: .claude/skills/orchestrating-knowledge-workflows/SKILL.md
        note: Converted from knowledge-coordinator-agent, guides /do on plan→build→improve sequence
      - location: .claude/commands/do.md
        note: 300+ lines, direct orchestration of expert agents (commit 353d576)

best_practices:
  - category: Frontmatter
    practices:
      - practice: Action verb descriptions for clarity
        evidence: .claude/agents/ pattern analysis
        timestamp: 2025-12-26
      - practice: Model defaults to sonnet unless specific need
        evidence: Most agents use sonnet
        timestamp: 2025-12-26
      - practice: Explicitly declare tools (don't rely on inheritance)
        evidence: Tool restriction patterns
        timestamp: 2025-12-26
      - practice: NEVER use colons in description field values
        evidence: Commit b6a2b47 fixed 38 agents with "Expects: SPEC" → "Expects SPEC" pattern
        timestamp: 2026-01-17
        implementation: |
          Colons in YAML string values break Claude Code's agent discovery parser.
          Agents with colons in descriptions will NOT appear in /agents list or selection UIs.
          Use "Expects USER_PROMPT" not "Expects: USER_PROMPT".
          Use "Returns summary of findings" not "Returns: summary of findings".
          This is a CRITICAL configuration error that silently breaks agent discoverability.
      - practice: Standardize color assignments by role within 4-agent expert pattern
        evidence: All 44 expert domain agents follow semantic color scheme (plan=yellow, build=green, improve=purple, question=cyan)
        timestamp: 2025-12-26
      - practice: Output-style field pattern applied to 55 agent files across all 13 domains
        evidence: |
          100% question agents: concise-reference (11/11)
          92% build agents: practitioner-focused (11/12, questions-build uses narrative-technical)
          Plan/improve agents: domain-sensitive (operational=practitioner-focused, content=academic/evidence-grounded)
        timestamp: 2025-12-28
        implementation: |
          Reference style in Instructions section with 2-3 inline reminders.
          Do NOT load full .claude/output-styles/{style}.md file into prompt.
          Operational domains prefer practitioner-focused across all phases.
          Content/research domains prefer academic-structured for planning, evidence-grounded for improvement.

  - category: Tool Selection
    practices:
      - practice: Read-only agents get Read/Grep/Glob only
        evidence: scout-agent.md pattern
        timestamp: 2025-12-26
      - practice: Orchestration moved to /do command directly (flat architecture)
        evidence: Commit 353d576 - coordinators converted to skills
        timestamp: 2025-12-26
      - practice: Plan agents get Write for spec caching to .claude/.cache/specs/
        evidence: All plan agents in experts/ have Write tool
        timestamp: 2025-12-26
      - practice: Improve agents get Bash for git history analysis
        evidence: All improve agents have Bash for git log/diff operations
        timestamp: 2025-12-26
      - practice: Question agents are strictly read-only (Read/Glob/Grep), use haiku model
        evidence: All 11 question agents follow this pattern
        timestamp: 2025-12-26
      - practice: Operational build agents (git, deployment) need Bash for command execution
        evidence: github-build-agent uses Bash for git/gh commands
        timestamp: 2025-12-26

  - category: Naming
    practices:
      - practice: Use kebab-case for agent names
        evidence: All agents in .claude/agents/
        timestamp: 2025-12-26
      - practice: Include role suffix (-agent, -coordinator, -orchestrator)
        evidence: Naming convention across agents
        timestamp: 2025-12-26
      - practice: Expert patterns use role suffixes (-plan-, -build-, -improve-, -question-)
        evidence: .claude/agents/experts/ structure, 4-agent pattern
        timestamp: 2025-12-26

  - category: Prompt Structure
    practices:
      - practice: Use ALL-CAPS for critical constraints (IMPORTANT, DO NOT)
        evidence: scout-agent.md Critical Constraints section
        timestamp: 2025-12-26
      - practice: Expertise sections are mutable, Workflow sections are stable
        evidence: Expert agent update patterns
        timestamp: 2025-12-26
      - practice: Expert domains include 450-750 line expertise.yaml as knowledge source
        evidence: All 12 expert domains have expertise.yaml
        timestamp: 2025-12-26
      - practice: Question agents reference expertise.yaml location in Expertise section
        evidence: "Load all [domain] knowledge from `.claude/agents/experts/[domain]/expertise.yaml`" pattern
        timestamp: 2025-12-26

  - category: Expertise Size Governance
    practices:
      - practice: All improve agents enforce expertise.yaml size limits to prevent unbounded accumulation
        evidence: Bulk update to 12 improve agents added SIZE GOVERNANCE block
        timestamp: 2025-12-28
        details: |
          **HARD LIMIT**: 1000 lines - file becomes unmanageable beyond this size
          **TARGET SIZE**: 750 lines - optimal for navigation and comprehension
          **WARNING THRESHOLD**: 900 lines - consolidate before next update

          When expertise.yaml exceeds 900 lines, improve agents execute:
          1. Prune entries >14 days old not referenced in recent git (past 30 days)
          2. Consolidate duplicate patterns (merge similar, reduce examples to 2-3)
          3. Move audit trails to expertise-audit.yaml when git_analysis_insights >100 lines
          4. Prune speculative content (keep top 3-5 potential_enhancements)

          Content classification:
          - KEEP: key_operations, decision_trees, patterns, best_practices, safety_protocols
          - ARCHIVE: git_analysis_insights >100 lines → expertise-audit.yaml
          - CONSOLIDATE: Similar patterns, redundant examples (5+ → 2-3)
          - PRUNE: potential_enhancements with no progress after 14 days
      - practice: Track expertise.yaml size as convergence metric
        evidence: Current sizes range from 455 lines (audit) to 1467 lines (external-teacher)
        timestamp: 2025-12-28
        details: |
          Domains >900 lines (need cleanup): agent-authoring (1384), external-teacher (1467),
          knowledge (1084), orchestration (940)

  - category: Architecture Patterns
    practices:
      - practice: Flat orchestration - /do spawns expert agents directly (not via coordinators)
        evidence: Commit 353d576 eliminated coordinator layer
        timestamp: 2025-12-26
      - practice: Convert coordinators to skills when they primarily delegate to experts
        evidence: Four coordinators converted to skills in .claude/skills/
        timestamp: 2025-12-26
      - practice: Skills are workflow templates, not executable agents (no frontmatter)
        evidence: Skills guide /do on plan→build→improve sequence
        timestamp: 2025-12-26
      - practice: 12 expert domains operational with 4-agent pattern (48 agents total)
        evidence: agent-authoring, audit, book-structure, claude-config, curriculum, do-management, external-teacher, github, knowledge, orchestration, questions, research
        timestamp: 2025-12-27
      - practice: Dual-file ownership - single expert domain manages tightly-coupled files
        evidence: curriculum domain owns both CURRICULUM.md and RUBRIC.md
        timestamp: 2025-12-27

known_issues:
  - issue: No automated validation for frontmatter completeness
    workaround: Manual review during agent creation
    status: open
    timestamp: 2025-12-26

  - issue: Tool restrictions can be bypassed via Bash
    workaround: Explicit defensive constraints in prompt ("NEVER use Bash")
    status: open
    timestamp: 2025-12-26

  - issue: Description length not enforced (some exceed 100 chars)
    workaround: Review descriptions for brevity; longer OK for discoverability
    status: accepted
    timestamp: 2025-12-26

potential_enhancements:
  - enhancement: Automated frontmatter validation on agent creation
    rationale: Catch missing required fields early
    effort: low
    timestamp: 2025-12-26

  - enhancement: Tool set templates by role
    rationale: Reduce configuration errors based on 4-agent pattern
    effort: low
    timestamp: 2025-12-26
    example: |
      Plan template: Read, Glob, Grep, Write
      Build template: Read, Write, Edit, Glob, Grep
      Improve template: Read, Write, Edit, Glob, Grep, Bash
      Question template: Read, Glob, Grep

  - enhancement: expertise.yaml scaffolding generator
    rationale: New expert domains need 450-750 line structured YAML
    effort: medium
    timestamp: 2025-12-26

stability:
  oscillation_detection:
    rule: |
      IF entry E1 at T1 contradicts E0 at T0
      AND entry E2 at T2 contradicts E1
      THEN oscillation detected
    resolution: |
      Preserve both with conflict marker
      Escalate to human
    detected_oscillations: []

  convergence_indicators:
    insight_rate_trend: "stable-high"
    contradiction_count: 0
    last_reviewed: 2026-01-17
    notes: |
      *[2026-01-17 - Post-description-colon-fix]*
      Critical configuration error discovered and fixed: colons in description field values
      cause silent agent discovery failures. Commit b6a2b47 fixed 38 agents across 12 domains.
      This learning added to best_practices (NEVER use colons) and key_operations pitfall section.

      New learnings added: +1 best practice, expanded pitfall evidence with commit reference
      Size after additions: ~772 lines (within healthy 750-900 range)

      *[2025-12-28 - Post-output-style implementation]*
      New learnings added: +1 pattern, +1 decision tree, +1 best practice, updates to key_operations
      Size after additions: ~800 lines (within healthy 750-900 range)

      Output-style field implementation learnings:
      - 100% consistency for question agents (concise-reference)
      - Domain-sensitive style selection more important than phase-based defaults
      - Operational domains prefer practitioner-focused throughout (not academic)
      - Questions workflow uses narrative-technical for conversational phases
      - Reference pattern (not full file) keeps prompts lean

      Cleanup cycle: Reduced from 1384 lines → ~750 lines (-634 lines, -45%)

      Cleanup actions taken:
      1. **Removed verbose examples**: Reduced 4-5 examples per operation to 2-3 representative ones
      2. **Consolidated duplicate patterns**: Merged coordinator_pattern with coordinator_to_skill_conversion_pattern
      3. **Removed resolved issues**: Deleted known_issues marked "resolved" (audit refactor, nested subagent)
      4. **Pruned redundant best_practices**: Consolidated overlapping entries, kept unique insights
      5. **Removed specialist patterns**: teaching_expert_pattern, curriculum_expert_pattern absorbed into dual_file_ownership_pattern
      6. **Removed standalone_agent_deprecation_pattern**: Temporary migration pattern, no longer needed
      7. **Simplified key_operations**: Removed document_timescale_learning (niche, rarely used)
      8. **Consolidated examples**: 1-2 per pattern instead of 3-4

      Content removed (major sections):
      - coordinator_pattern (47 lines) - merged into coordinator_to_skill_conversion_pattern
      - specialist_agent_pattern (25 lines) - deprecated pattern
      - teaching_expert_pattern (82 lines) - niche, absorbed into dual_file_ownership
      - curriculum_expert_pattern (47 lines) - duplicate of dual_file_ownership
      - standalone_agent_deprecation_pattern (89 lines) - temporary migration pattern
      - document_timescale_learning (47 lines) - niche operation, rarely referenced
      - Resolved known_issues (2 entries, 25 lines total)
      - Redundant best_practices entries (~80 lines)
      - Verbose examples in key_operations (~150 lines)

      Core knowledge preserved:
      - All 6 key_operations (write_agent_frontmatter, select_tools_by_role, select_model_for_agent,
        write_agent_description, structure_agent_prompt, migrate_safety_protocols_to_expert)
      - All 3 decision_trees (tool_selection_by_role, model_selection_by_complexity, description_pattern_selection)
      - Core patterns (expert_4agent_pattern, read_only_agent_pattern, question_agent_pattern,
        absorb_standalone_into_expert_pattern, dual_file_ownership_pattern, coordinator_to_skill_conversion_pattern)
      - All safety_protocols references
      - Size governance best_practices (critical for all domains)

      Stability indicators:
      - Core patterns stable since commit 353d576
      - Color scheme standardized across all domains
      - Zero contradictions detected
      - File size now at healthy 750-line target
