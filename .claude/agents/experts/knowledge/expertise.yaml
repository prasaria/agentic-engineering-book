# Knowledge Management Expertise
# Target: 750 lines | Domain: Operational knowledge for book content management
# Size: 782 lines (pruned from 994 on 2026-02-02, added swarm documentation learnings)

overview:
  description: |
    Knowledge management and content capture—entry location decision tree,
    content structure patterns, voice guidelines, linking strategies, and
    question-driven development. This expertise enables correct placement,
    organization, and development of book content.
  scope: |
    Covers book directory structure (chapters/, appendices/), content frontmatter,
    entry type decisions (new vs extend), inline timestamp patterns, voice guidelines,
    cross-reference strategies, and question file management. Does NOT cover agent
    authoring (see agent-authoring expert) or book structure mechanics like TOC
    generation (see book-structure expert).
  rationale: |
    Effective knowledge capture enables insights to be discoverable, properly
    contextualized, and integrated with related content. Poor knowledge management
    leads to fragmented insights, lost context, and duplication.
  terminology:
    official_terms:
      subagents: "Task tool - agents that report back to orchestrator only (no peer messaging)"
      agent_teams: "TeammateTool - independent Claude Code sessions with peer-to-peer messaging and shared task lists"
      team_lead: "Main session that creates agent team via CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1"
      teammates: "Independent Claude Code sessions coordinated through TeammateTool operations"
      feature_gate: "CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1 env var enables agent teams (previously claude-sneakpeek only)"
    documentation: "https://code.claude.com/docs/en/agent-teams"
    official_status: "Experimental, disabled by default in Claude Code 2.0.76+. Environment variable enables access."

core_implementation:
  primary_files:
    - path: chapters/
      purpose: All book content organized by parts and chapters
    - path: appendices/examples/
      purpose: Real project configurations and examples
    - path: .journal/
      purpose: Timestamped personal thoughts (hidden, private)
    - path: CLAUDE.md
      lines: 34-117
      purpose: Book structure conventions and content conventions
    - path: STYLE_GUIDE.md
      purpose: Voice, evidence standards, structural requirements

  key_patterns:
    - name: Entry Location Decision
      summary: Where new content belongs based on topic area
    - name: Inline Timestamp Pattern
      summary: Adding dated insights to existing content
    - name: Question-Driven Development
      summary: Using _questions.md to guide chapter expansion
    - name: Cross-Reference Pattern
      summary: Bidirectional linking between related content

key_operations:
  determine_entry_location:
    name: Determine Where Content Belongs
    description: Decide location for new insights in the book structure
    when_to_use: Capturing new insights, adding content, expanding topics
    approach: |
      Use decision_trees > entry_location_framework for full mapping.
      Quick reference: Part 1 (foundations), Part 2 (patterns/practices),
      Part 3 (mental models/tools), Part 4 (examples/appendices).
      Then: extend existing vs create new (see new_vs_extend_decision tree).

  choose_new_vs_extend:
    name: Create New Entry vs Extend Existing
    description: Decide whether to create new file or extend existing content
    when_to_use: Adding new insights that relate to existing content
    approach: |
      Extend existing entry when:
      - Insight directly relates to existing content scope
      - Adds nuance or example to established pattern
      - Answers question posed in entry
      - Fills gap in existing coverage

      Create new entry when:
      - Insight doesn't fit existing entry's scope
      - Topic warrants dedicated exploration
      - Content is significantly different from existing
      - Likely to grow independently
    examples:
      - scenario: New prompt structuring technique
        decision: Extend chapters/2-prompt/2-structuring.md
        reasoning: Fits existing scope, adds to pattern catalog
      - scenario: New mental model about agent loops
        decision: Create chapters/8-mental-models/N-new-model.md
        reasoning: Distinct concept, warrants dedicated exploration

  apply_voice_guidelines:
    name: Apply Voice and Tone Guidelines
    description: Ensure content matches established voice patterns
    when_to_use: Writing or reviewing any book content
    approach: |
      See best_practices > Voice and Tone for comprehensive guidance.
      Key principles: third-person throughout, avoid hedging, imperative mood
      for instructions, bold assertion + elaboration for mental models.

  use_inline_timestamps:
    name: Add Timestamped Inline Additions
    description: Extend existing content with dated insights
    when_to_use: Adding new learning to existing section without restructuring
    approach: |
      Format: *[YYYY-MM-DD]*: Insight text here...

      When to use:
      - Adding new learning to existing section
      - Documenting experiential observation
      - Noting pattern discovered in implementation
      - Recording evolution of understanding

      Placement:
      - Add after related content in section
      - Group related timestamp entries together
      - Maintain chronological order within groups
    examples:
      - scenario: New insight about context management
        format: |
          *[2025-12-08]*: Multi-agent systems benefit from explicit context handoff
          protocols. Without clear boundaries, context can drift between agents.
      - scenario: Pattern from implementation
        format: |
          *[2025-12-09]*: Decision framework pattern from model-selection.md -
          ASCII flowcharts communicate decision processes more clearly than prose.

  manage_question_development:
    name: Use Questions to Drive Content Development
    description: Leverage _questions.md files to guide chapter expansion
    when_to_use: Planning content development, expanding chapters
    approach: |
      See patterns > question_file_pattern for comprehensive guidance.
      Key principle: Answers go in chapter content, NOT in _questions.md.
      _questions.md tracks state only using markers: (unmarked), [partial],
      [answered], [stale], [deferred].

  implement_cross_references:
    name: Create Effective Cross-References
    description: Link related content with contextual explanations
    when_to_use: Connecting related concepts across chapters
    approach: |
      Link patterns:
      - Use relative paths from current file
      - Include section anchors when specific: path.md#section
      - Add contextual explanation (why connection matters)

      Bidirectional linking:
      - When linking from A to B, also add link from B to A
      - Both links should explain the relationship

      Enhanced cross-reference format:
      Before (minimal):
      - **To [Tool Use](path.md):** Tool descriptions are prompts

      After (contextual):
      - **To [Tool Use](path.md):** Tool descriptions are prompts themselves.
        Poor tool docs lead to misuse regardless of main prompt quality.
    pitfalls:
      - what: Generic "click here" link text
        why: No context, poor for scanning
        instead: Descriptive text explaining the connection
      - what: One-directional links only
        why: Misses discovery opportunity from other side
        instead: Add bidirectional links

decision_trees:
  entry_location_framework:
    name: Entry Location Decision Tree
    entry_point: What is the content about?
    branches:
      - condition: Core concepts (prompts, models, context, tools)
        action: Part 1 - Foundations (chapters 1-5)
        sub_branches:
          - condition: Four pillars overview, leverage points
            action: chapters/1-foundations/
          - condition: Prompt structure/types/patterns
            action: chapters/2-prompt/
          - condition: Model selection/behavior/limitations
            action: chapters/3-model/
          - condition: Context management/loading/strategies
            action: chapters/4-context/
          - condition: Tool design/selection/restrictions
            action: chapters/5-tool-use/
      - condition: Patterns and practices
        action: Part 2 - Craft (chapters 6-7)
        sub_branches:
          - condition: Recurring architectural pattern
            action: chapters/6-patterns/
          - condition: Operational practice (debugging, eval, production)
            action: chapters/7-practices/
      - condition: Mental models and tooling
        action: Part 3 - Perspectives (chapters 8-9)
        sub_branches:
          - condition: Thinking framework or design principle
            action: chapters/8-mental-models/
          - condition: Specific tool documentation
            action: chapters/9-practitioner-toolkit/
      - condition: Examples and implementations
        action: Part 4 - Appendices (appendices/examples/)

  new_vs_extend_decision:
    name: Create New Entry vs Extend Existing
    entry_point: Does related content exist?
    branches:
      - condition: No existing coverage of topic
        action: Create new entry with appropriate frontmatter
      - condition: Existing entry covers related ground
        sub_branches:
          - condition: New content fits existing scope
            action: Extend existing entry with new section
          - condition: New content warrants dedicated exploration
            action: Create new entry, link from existing
          - condition: New content is a nuance or example
            action: Add inline with timestamp

  entry_scope_decision:
    name: Entry Scope Planning
    entry_point: How comprehensive should this entry be?
    branches:
      - condition: Chapter introduction (_index.md)
        action: Brief overview with links to sections (50-100 lines)
      - condition: Concept introduction
        action: Initial framing with leading questions (100-200 lines)
      - condition: Comprehensive reference
        action: Full pattern catalog with examples (400-650 lines)
      - condition: Mental model
        action: Focused framework with metaphors (150-250 lines)

patterns:
  content_structure_pattern:
    name: Standard Developed Entry Structure
    context: Fully developed chapter sections
    implementation: |
      Structure flow: questions → mental model → patterns

      1. Core Questions (categorized by theme)
         - Surface what the entry addresses
         - Provide navigation aid

      2. Your Mental Model
         - Bold assertion with practical elaboration
         - Frame conceptual understanding

      3. Domain Content
         - Patterns, implementations, examples
         - Actionable details

      4. Connections
         - Links to related entries with context
    trade_offs:
      - advantage: Multiple entry points for different reader needs
        cost: More structure to maintain
      - advantage: Questions explicitly acknowledge uncertainty
        cost: Requires thinking about what's unknown
    real_examples:
      - location: chapters/2-prompt/2-structuring.md
        note: Comprehensive entry with Core Questions, Mental Model, patterns

  inline_addition_pattern:
    name: Inline Timestamped Addition
    context: Adding insights to existing content without restructuring
    implementation: |
      Format: *[YYYY-MM-DD]*: New insight...

      Use cases:
      - Adding new learning to existing section
      - Documenting experiential observation
      - Noting pattern discovered in implementation

      Example:
      ## Context Management

      Effective context management requires careful prioritization.

      *[2025-12-08]*: Multi-agent systems benefit from explicit context
      handoff protocols. Without clear boundaries, context can drift.
    trade_offs:
      - advantage: Tracks when learning was captured
        cost: Visual noise in content
      - advantage: Preserves existing structure
        cost: May fragment related insights

  question_file_pattern:
    name: Question File Development Pattern
    context: Using _questions.md to drive content development
    implementation: |
      Purpose: Generative scaffolding, NOT book output

      Structure:
      - Questions grouped by theme/subtopic
      - State markers track progress
      - References to content that answers questions

      States:
      - (unmarked) - Fresh, unanswered
      - [partial] - Started, needs expansion
      - [answered] - Comprehensive coverage exists
      - [stale] - May need revisiting
      - [deferred] - Skipped intentionally

      Key principle:
      - Answers go in chapter content files
      - _questions.md tracks state only
    real_examples:
      - location: chapters/2-prompt/_questions.md
        note: Questions organized by theme with state tracking

  leading_questions_pattern:
    name: Leading Questions for New Entries
    context: Seeding new entries with questions for future development
    implementation: |
      ## Leading Questions

      - How does this pattern scale across different model sizes?
      - What are the failure modes when context exceeds limits?
      - How do you measure effectiveness of this approach?

      Purpose:
      - Guide future development
      - Explicitly acknowledge uncertainty
      - Create roadmap for expansion
    trade_offs:
      - advantage: Makes entry developable by others
        cost: Entry feels incomplete until answered

  contextual_cross_reference_pattern:
    name: Contextual Cross-References (Evolved Pattern)
    context: Linking related content with explanation. Enhanced via commit d69ef22 learnings.
    implementation: |
      ## Connections section format:
      - **To [Topic](relative/path.md)**: Why this connection matters.
        Additional context about the relationship.

      Enhanced contextual format:
      - **To [Tool Use](../5-tool-use/_index.md):** Tool descriptions are prompts
        themselves. Poor tool docs lead to misuse regardless of main prompt quality.

      For changelog integrations (NEW):
      - Use comparison tables to show feature trade-offs (not just describing separately)
      - Link to mental models through pattern explanations, not just tool features
      - Group related features under thematic headers before creating separate sections
      - Example: Real-Time Message Steering links conceptually to Progressive Refinement

      Add 1-2 sentences per link explaining:
      - Why the connection matters (conceptual bridge)
      - What insight readers should transfer between sections
    real_examples:
      - location: chapters/2-prompt/_index.md
        note: Basic Connections section
      - location: chapters/9-practitioner-toolkit/1-claude-code.md lines 337-366
        note: Unified Mental Model with comparison table (Skills vs Slash Commands)
      - location: chapters/9-practitioner-toolkit/1-claude-code.md lines 651-698
        note: Hook Context Injection with Block vs Context Injection decision table

best_practices:
  - category: Content Placement
    timestamp: 2025-12-26
    practices:
      - practice: Check existing content before creating new entries (CLAUDE.md:169)
      - practice: Prefer extending existing files over creating new ones (CLAUDE.md:170)
      - practice: Use entry location decision tree for placement

  - category: Voice and Tone
    timestamp: 2025-12-26
    practices:
      - practice: Use direct statements over hedging (STYLE_GUIDE.md)
      - practice: Third-person only throughout (STYLE_GUIDE.md:17-24, commit 26f7974)
      - practice: Bold assertion + elaboration for mental models (pit-of-success.md)
      - practice: Imperative mood for instructions (STYLE_GUIDE.md:37-44)

  - category: Content Structure
    timestamp: 2025-12-26
    practices:
      - practice: Lead with Core Questions for developed entries (commit 0322625)
      - practice: Use three-tier structure (questions → mental model → patterns)
      - practice: Tables for comparing 3-7 options across dimensions
      - practice: Lead complex patterns with concrete examples before abstraction
      - practice: Use timestamped inline additions for variant patterns

  - category: Evidence-Grounded Content
    practices:
      - practice: Comprehensive evidence sections with research citations
        evidence: chapters/2-prompt/3-language.md (commit a624250) - 635 lines with academic papers, official docs, practitioner sources
        rationale: Long-form evidence-based chapters establish credibility and provide actionable research-backed guidance
        timestamp: 2025-12-26
      - practice: Structure research findings with clear tables showing quantified impact
        evidence: 3-language.md uses tables for task-type dependency, specificity calibration, model-specific patterns
        rationale: Tables enable quick scanning of evidence and direct comparison of approaches
        timestamp: 2025-12-26
      - practice: Separate academic papers, official documentation, and practitioner sources in references
        evidence: 3-language.md references section (lines 576-623) categorizes source types
        rationale: Clarifies evidence strength and helps readers assess claim validity
        timestamp: 2025-12-26
      - practice: Include arxiv IDs and specific paper names for reproducibility
        evidence: 3-language.md includes arxiv IDs like "SatLM arxiv:2305.09656" and "DETAIL Framework arxiv:2512.02246"
        rationale: Enables readers to verify claims and dive deeper into research
        timestamp: 2025-12-26
      - practice: Use "Open Questions" section to acknowledge uncertainty
        evidence: 3-language.md ends with open research questions (lines 625-633)
        rationale: Models intellectual humility and guides future exploration
        timestamp: 2025-12-26

  - category: Cross-References & Question Management
    timestamp: 2025-12-26
    practices:
      - practice: Bidirectional linking with contextual explanation (commit a72bcf2)
      - practice: Update related index files when adding content
      - practice: Answers go in chapter content, not in _questions.md
      - practice: Update question states immediately after addressing

  - category: Constraint Framing
    practices:
      - practice: Frame constraints as positive requirements, not prohibitions
        evidence: chapters/2-prompt/3-language.md lines 188-263 conversion table
        rationale: Negative constraints ("never do X") backfire at scale; positive framing reduces semantic activation of unwanted patterns
        timestamp: 2025-12-26
        example: "|Never use global state|Use dependency injection|"

  - category: Multi-Agent Swarm Content Updates
    practices:
      - practice: Coordinate large content updates via parallel agent swarms
        evidence: Commit 20500f1 (2026-01-30) - 10 agents, 11 tasks, ~4 minutes
        rationale: Enables simultaneous pattern entry creation + debugging expansion + cross-reference fixes
        timestamp: 2026-01-30
      - practice: Create comprehensive pattern entries (300-550 lines) with full structure
        evidence: ReAct (320 lines), HITL (551 lines), Progressive Disclosure (307 lines)
        rationale: Swarm capacity allows depth without sacrificing breadth
        timestamp: 2026-01-30
      - practice: Fix cross-reference drift as part of swarm coordination
        evidence: Commit 20500f1 fixed 15 broken cross-references across 10 files
        rationale: Swarm can address infrastructure debt alongside feature work
        timestamp: 2026-01-30

known_issues:
  - issue: Voice consistency can drift across long entries
    workaround: Review against voice guidelines during editing
    status: open
    timestamp: 2025-12-26

  - issue: False technical claims can propagate before validation
    workaround: Verify technical assertions against actual implementation
    context: Commit 26f7974 removed ~600 lines of hook enforcement claims proven false
    status: resolved
    timestamp: 2025-12-26
    learning: Technical claims about code capabilities must be verified against actual implementation, not assumed from documentation

  - issue: Question states can drift out of sync with content
    workaround: Periodic review of question files against chapter content
    status: open
    timestamp: 2025-12-26

  - issue: Cross-references can become stale when content moves
    workaround: Search for broken links after restructuring
    status: open
    timestamp: 2025-12-26

  - issue: Inline timestamps create visual noise
    workaround: Consider consolidating into dedicated sections for mature entries
    status: accepted
    timestamp: 2025-12-26

  - issue: Research-heavy chapters require significant time investment
    workaround: Plan for 20+ hours when committing to comprehensive evidence-based content
    context: chapters/2-prompt/3-language.md took substantial research effort
    status: accepted
    timestamp: 2025-12-26

documenting_system_patterns:
  name: Documenting System-Level Patterns (Multi-Agent Architectures)
  context: Pattern from chapters/6-patterns/2-self-improving-experts.md expansion
  timestamp: 2025-12-26

  pattern_observed: |
    System-level patterns (multi-agent architectures) require 5-section structure:

    1. **Evolution Timeline Table** - commit history as narrative backbone
       (chronological: hash | date | change | impact, highlight CRITICAL pivots)

    2. **System-Level Benefits Comparison** - emergent properties vs individual
       (before/after table showing dimensions like consistency, boundaries, clarity)

    3. **Template Documentation** - reusable pattern with real examples
       (role breakdown, tool allocation, frontmatter from actual files with line numbers)

    4. **Structured Schema** - detailed knowledge format specification
       (sections with purpose/structure/examples, line count targets, mutability strategy)

    5. **Case Study** - concrete application with quantified metrics
       (8-step process, before/after comparison, ROI calculation)

  key_techniques:
    - Git commits as verifiable evidence (commit hashes link to actual diffs)
    - Every claim backed by file path + line numbers
    - Real quantified metrics from actual usage (not theoretical estimates)
    - Tables for quick scanning (evolution, benefits, templates, comparisons)
    - Incremental growth via timestamped sections (preserves base + shows evolution)

  when_to_use:
    - Multi-agent system architectures (3+ coordinated agents)
    - Evolution from individual pattern to system paradigm
    - Reusable templates needing comprehensive reference

  real_examples:
    - location: chapters/6-patterns/2-self-improving-experts.md (lines 643-1465)
      note: 822 lines with 15+ commits, 20+ file paths, 10+ metrics, 5 tables

comprehensive_research_chapter_pattern:
  name: Comprehensive Evidence-Based Chapter Pattern
  context: Pattern from chapters/2-prompt/3-language.md creation (commit a624250)
  timestamp: 2025-12-26

  pattern_observed: |
    Creating substantial research-backed chapters (400-650 lines) that synthesize
    academic papers, official documentation, and practitioner sources into
    authoritative technical reference material.

    Structure for evidence-based chapters:
    1. Opening: Clear scope and relevance statement (what's covered, why it matters)
    2. Multiple focused sections (5-7 major topics per chapter)
    3. Evidence integration: Inline citations with quantified claims
    4. Comparison tables showing approaches across dimensions
    5. Anti-patterns section demonstrating what NOT to do
    6. Model-specific guidance when relevant (Claude, GPT, Gemini)
    7. Comprehensive references section (categorized by source type)
    8. Open questions section acknowledging research gaps

  key_metrics:
    evidence_density: "~15-20 citations per 600 lines"
    structure_ratio: "70% patterns/guidance, 20% examples, 10% references"
    time_investment: "Plan for 20+ hours of research and synthesis"
    source_categories: "3 types - academic papers, official docs, practitioner sources"

  when_to_use:
    - Foundational topics where evidence-grounded guidance provides long-term reference value
    - Areas with significant academic/industry research to synthesize
    - Topics where practitioners need verifiable, authoritative claims
    - Content that will be cited or referenced extensively

  trade_offs:
    - advantage: Establishes authoritative, verifiable guidance
      cost: Requires significant research investment (20+ hours)
    - advantage: Long-term reference value for practitioners
      cost: Higher maintenance burden as research evolves
    - advantage: Enables readers to verify claims and explore deeper
      cost: More complex to write and structure than experience-based content

  real_examples:
    - location: chapters/2-prompt/3-language.md
      lines: 635 total
      sections: 9 major sections
      citations: "9 academic papers, 3 official docs, 4 practitioner sources"
      tables: 6 comparison/analysis tables
      note: "Synthesized 75+ sources into coherent practitioner guidance"

recent_content_learnings:
  swarm_content_generation:
    name: Parallel Agent Swarm Implementation Patterns (Commit 20500f1)
    context: 10-agent knowledge base overhaul with production metrics
    timestamp: 2026-01-30
    pattern_observed: |
      Production swarm execution generates 3,082 lines across 20 files in ~4 minutes (10×
      speedup vs sequential). Quality patterns: 3 new pattern entries (320-551 lines each),
      15 cross-reference fixes bundled with features, comprehensive structure maintained
      across all parallel agents. Coordination includes: infrastructure debt repair, pattern
      selection framework for _index.md, bundled example documentation (KotaDB case study).

      **When to use:** Multiple independent content areas (4+ tasks), 1000+ line expansion
      across diverse topics, infrastructure debt with time pressure. **Trade-offs:** 10×
      speedup vs coordination overhead + token consumption. **Key techniques:** Pattern
      selection decision framework, cross-reference repair as swarm task, bundled infrastructure
      fixes prevent debt accumulation.

    evidence: |
      Commit 20500f1: 10 agents → 3 patterns (ReAct 320L, HITL 551L, Progressive Disclosure 307L),
      2 toolkit entries, 1 expansion (Debugging 250→1030L), 2 examples, 15 link repairs across
      10 files, pattern selection framework in chapters/6-patterns/_index.md. Time: ~4 minutes.
      Quality: Full structure (Questions, Model, Trade-offs, Connections) maintained uniformly.

    when_to_use:
      - Large-scale content expansion requiring consistent quality across parallel work
      - Infrastructure debt (broken links) bundled with feature work
      - Time-sensitive delivery (book releases, course launches)

external_research_integration:
  name: Claude-Sneakpeek Research Integration Pattern
  context: Integration of multi-agent orchestration research from community tools into book content
  timestamp: 2026-01-30
  pattern_observed: |
    External research integration reveals sophisticated orchestration patterns that enhance
    foundational content with evidence-grounded learnings. The claude-sneakpeek research
    (Kimi K2.5 swarm mode, TeammateTool feature gates, cc-mirror orchestration skills)
    was successfully integrated across 4 key files without losing existing voice or structure.

    **Integration Strategy:**
    1. **Lightweight Injection Points**: Added timestamped insights to existing sections
       (e.g., Model-Native Swarm section in multi-model-architectures.md)
    2. **Dedicated New Sections**: TeammateTool warranted its own comprehensive section
       (claude-code.md lines 245-524, 280 lines)
    3. **Rich Cross-Reference Anchoring**: Added explicit connections from new content to
       related chapters (orchestrator-pattern.md → multi-model-architectures.md)
    4. **Bidirectional Navigation**: Both orchestrator pattern and multi-agent context updated
       to reference new TeammateTool capabilities

    **Content Quality Maintained:**
    - Voice consistency preserved (third-person, evidence-grounded style)
    - Newcomer cross-references included (TeammateTool to Task comparison table)
    - Mental models explicit (Your Mental Model section for TeammateTool)
    - Trade-offs documented (three-tier spawn strategy, coordination pattern selection)

  key_techniques:
    - Staged integration: Metadata first (brief mention), then full section (comprehensive)
    - Comparative framing: Always position new content against known patterns (Task vs TeammateTool)
    - Source attribution: Include commit hashes and external URLs for traceability
    - Temporal anchoring: Use timestamps to show when external patterns were discovered
    - Forward links: Add "See Also" sections even in non-deterministic exploration

  evidence: |
    **Commit de68e9f (2026-01-30)**: TeammateTool and model-native swarm documentation
    - Added Model-Native Swarm Orchestration section (multi-model-architectures.md)
    - Added TeammateTool section (claude-code.md, 280 lines, 5 coordination patterns)
    - Added Feature Gate Reverse Engineering section (claude-code.md, 190 lines)
    - Cross-reference updates to orchestrator-pattern.md and execution-topologies.md

    **Commit 20500f1 (2026-01-30)**: Knowledge base overhaul expanding research patterns
    - Orchestrator pattern extended: 417 → 674 lines (257 line addition)
    - Added Conductor Philosophy (communication excellence patterns)
    - Added Read vs Delegate Guidelines (1-2 file threshold heuristic)
    - Added Background Execution Mechanics (run_in_background usage)
    - Added Pattern Composition (PR review, feature implementation, bug diagnosis)

    **Files Modified by Research Integration:**
    - chapters/3-model/1-model-selection.md: Multi-Agent Model Selection section
    - chapters/5-tool-use/1-tool-design.md: Rich User Questioning Patterns (4×4 maximal)
    - chapters/6-patterns/3-orchestrator-pattern.md: Conductor philosophy + composition patterns
    - chapters/9-practitioner-toolkit/1-claude-code.md: TeammateTool + feature gates

  when_to_use:
    - Integrating external research (community tools, published papers, practitioner blogs)
    - Filling gaps identified in current documentation
    - Adding evidence for existing patterns with new concrete examples
    - Cross-domain pattern discovery from other specialized communities

  complex_system_pattern_documentation:
    name: Complex System Pattern Documentation (12-Section Structure)
    context: Expert Swarm Pattern (532 lines, commit a1d5942)
    timestamp: 2026-02-02
    pattern_observed: |
      Multi-agent architectural patterns require comprehensive documentation structure:
      Problem → Structure (ASCII) → Hybrid Positioning → Protocol Spec → Communication →
      Learning Separation → Scale → Implementation → Trade-offs → Decision Framework →
      Connections → Open Questions.

      **Key structural elements (consolidated from 4 sub-patterns):**

      1. Production evidence anchor: Open with commit hash + metrics (10 agents, 4 min, 3,082 lines)
      2. ASCII diagram early: Visual before prose (Lead → expertise.yaml → Workers → Join)
      3. Hybrid approach positioning: Frame new pattern vs existing (Traditional/Expert Swarm/Model-Native)
      4. Protocol specification: Concrete syntax, not abstractions (EXPERTISE_PATH: /absolute/path)
         - Include "Why Not X?" comparison table (context copying vs path-passing)
      5. Scale with evidence: Wall-clock comparison (4 min parallel vs 40 min sequential = 10× speedup)
      6. Token economics transparency: Cost analysis (750-line expertise = 3,000 tokens/worker)
      7. Implementation examples: Real prompts from production (commit 20500f1)
      8. Three-way trade-off table: 3 alternatives × 11 dimensions (scannability > prose)
      9. ASCII decision tree: Binary nodes force reader thinking (better than prose "use when")
      10. Good Fit/Poor Fit bullets: Fast-path before decision tree
      11. Bidirectional connections: 6+ links with relationship explanations
      12. Open Questions (8+): Acknowledge research gaps (consistency, scale, observability)

    evidence: |
      chapters/6-patterns/8-expert-swarm-pattern.md (532 lines)
      12 major sections, 5 cross-reference updates, production evidence from commit 20500f1

    when_to_use:
      - Multi-agent architectural patterns (3+ components)
      - Patterns with quantified production evidence
      - Protocols requiring specification (EXPERTISE_PATH, message passing)

    key_techniques:
      - Production evidence first, ASCII diagrams before prose
      - Comparison tables justify design choices
      - Decision trees over prose lists
      - Open Questions preserve credibility

  slash_command_documentation_pattern:
    name: Slash Command Documentation Structure (623 lines)
    context: /do-swarm command (.claude/commands/do-swarm.md, commit a1d5942)
    timestamp: 2026-02-02
    pattern_observed: |
      Slash commands requiring multi-step workflows benefit from imperative instruction
      format with 7-section structure: Role → Workflow (7 steps) → Templates → Coordination →
      When To Use → Examples → Troubleshooting.

      **Structural pattern:**
      - "Your Role" section: 3 bullets clarifying command executor responsibilities
      - Workflow as numbered steps: Step 1 (Create Team) → Step 7 (Cleanup)
      - Each step has: description + code block + constraints
      - "Teammate Prompting Format" section: Copy-paste templates (Lead + Worker)
      - Critical callouts: "CRITICAL: Spawn all workers in a SINGLE message"

      **Template format (within command docs):**
      - Lead agent template: 8 sections (ROLE, CONTEXT, TASK, CONSTRAINTS, OUTPUT FORMAT)
      - Worker agent template: Same 8 sections, different content
      - EXPERTISE_PATH: line in CONTEXT section (absolute path)
      - Allowed tools listed explicitly in CONSTRAINTS

      **Decision guidance:**
      - "When to use /do vs /do-swarm" comparison table
      - "/do" for sequential workflows (plan→build→improve)
      - "/do-swarm" for parallel coordination requiring inter-agent messaging

    evidence: |
      .claude/commands/do-swarm.md (623 lines)
      - Sections: Role (1), Workflow (7 steps), Templates (2), Coordination, When/Examples, Troubleshooting
      - Templates include EXPERTISE_PATH protocol
      - 7-step workflow mirrors actual swarm execution

    when_to_use:
      - Multi-step commands requiring coordination
      - Commands with domain expert integration (expertise.yaml passing)
      - Parallel execution workflows

    key_techniques:
      - Imperative instructions ("You do NOT do the work yourself")
      - Code block templates (copy-paste ready)
      - Critical callouts for common errors
      - Step-by-step workflow matching execution order

  debugging_chapter_expansion_pattern:
    name: Debugging Chapter Expansion (250→1030 lines)
    context: chapters/7-practices/1-debugging-agents.md expansion (commit 20500f1)
    timestamp: 2026-02-02
    pattern_observed: |
      Debugging content expanded from 250 → 1,030 lines (4× growth) by adding:
      1. Agent vs Traditional Debugging comparison table (mindset shift)
      2. Core Four Framework table (Prompt/Model/Context/Tools diagnostic sequence)
      3. 6-branch diagnostic decision tree (Step 1: Characterize → Step 2A-F: Root cause)
      4. 8+ common failure modes (Context Overflow, Tool Errors, Hallucination, etc.)
      5. Symptom → Diagnosis → Root Cause → Fixes structure for each failure mode

      **Structure for failure mode documentation:**
      - **Symptoms**: Observable behaviors (agent forgets early instructions)
      - **Diagnosis**: How to verify (check token count vs context limit)
      - **Root causes**: Why it happens (3-4 bullets)
      - **Fixes**: Remediation strategies (4-5 bullets)

      **Effective patterns:**
      - Comparison tables for mindset shifts (deterministic vs probabilistic)
      - Decision trees for diagnostic workflows (if X then check Y)
      - Symptom-first organization (readers start with what they observe)
      - Multiple failure modes in single chapter (comprehensive reference)

    evidence: |
      chapters/7-practices/1-debugging-agents.md (250 → 1,030 lines)
      - Added: Debugging Mindset, Core Four Framework, 6-branch diagnostic tree
      - Added: 8 common failure modes (structured as Symptoms/Diagnosis/Root/Fixes)
      - Preserved: Original chapter opener and connections section

    when_to_use:
      - Expanding stub chapters with comprehensive operational guidance
      - Documenting troubleshooting workflows
      - Building practitioner reference material

    key_techniques:
      - Symptom-first structure (readers search by what they see)
      - Decision trees for diagnostics (structured troubleshooting)
      - Comparison tables for mindset (agent vs traditional code)
      - Structured failure mode template (4-part format)

agent_teams_documentation:
  name: Large Multi-File Feature Documentation
  context: Agent Teams (TeammateTool) multi-file update (2026-02-05)
  timestamp: 2026-02-05
  pattern_observed: |
    Agent teams documentation required coordinated updates across 6+ files
    with interdependencies and terminology synchronization. Successful
    execution depended on phased approach: foundation first, then
    dependents. Key learnings for similar large documentation efforts.

    **Phase 1: Foundation (Core Concepts)**
    - chapters/9-practitioner-toolkit/1-claude-code.md: Added "Agent Teams" section (420 lines, lines 246-667)
    - Comprehensive coverage: Prerequisites, Core Capabilities, Display Modes, Keyboard Controls, Getting Started,
      Advanced Features, Coordination Patterns, Best Practices, Troubleshooting, Limitations, Decision Framework
    - Updated terminology section to include official status and feature gate migration

    **Phase 2: Command Documentation**
    - .claude/commands/do-swarm.md: Updated prerequisites, display modes, limitations (623 lines)
    - Mirrored terminology from official docs
    - Added explicit CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1 instructions
    - Included validation patterns for feature availability

    **Phase 3: Dependent Patterns**
    - chapters/6-patterns/8-expert-swarm-pattern.md: Added Agent Teams Messaging subsection (lines 153-172)
    - chapters/6-patterns/3-orchestrator-pattern.md: Updated Agent Teams references
    - chapters/4-context/4-multi-agent-context.md: Added agent teams vs subagents section

    **Phase 4: Expertise Updates**
    - 13 expert domain expertise.yaml files: Updated terminology and cross-references
    - CLAUDE.md: Updated feature gate references in documentation tables

  key_techniques:
    - Phased execution prevents broken references during updates
    - Foundation-first approach ensures terminology consistency
    - Cross-file terminology defined in official docs (code.claude.com), then propagated
    - Display modes documented in command level first, then referenced from chapter docs
    - Official limitations section acts as single source of truth

  critical_learnings:
    - Feature gate migration: claude-sneakpeek internal → CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS public env var
    - Official terminology distinction maintained throughout: "agent teams" (peer messaging) vs "subagents" (report-back)
    - Prerequisites section critical when feature is experimental/gated (enables/verification pattern)
    - Display modes (in-process vs split-pane) are user-facing, must be documented early in chapter
    - Limitations section requires continuous updates as feature matures (6 limitations documented as of 2026-02-05)

  when_to_use:
    - Large documentation efforts spanning 5+ files
    - Features with experimental status requiring explicit enablement
    - Cross-system terminology requiring consistency (chapter + command + expertise)
    - Multi-phase rollouts where dependencies are critical

  evidence: |
    - chapters/9-practitioner-toolkit/1-claude-code.md: 420-line Agent Teams section (2026-02-05)
    - .claude/commands/do-swarm.md: Updated prerequisites + display modes (2026-02-05)
    - chapters/6-patterns/8-expert-swarm-pattern.md: Agent Teams Messaging subsection
    - Terminology synchronized across 14 files (1-claude-code.md, do-swarm.md, 6 chapter files, 6 expertise.yaml files, CLAUDE.md)
    - Official docs (code.claude.com) serve as authoritative source

  anti_patterns:
    - what: Updating dependent files before foundation
      why: Broken cross-references, terminology inconsistency
      instead: Update foundation (claude-code.md), validate, then cascade updates
    - what: Duplicating prerequisites across command + chapter docs
      why: Maintenance burden when feature status changes
      instead: Reference official prerequisites once, link from dependent docs
    - what: Vague status ("available soon", "in development")
      why: No clear enablement path for readers
      instead: Specific version (2.0.76+), explicit env var, verification steps

memory_management_documentation:
  name: Memory Management Feature Documentation (310 lines)
  context: Session memory + .claude/rules/ system documentation (chapters/9-practitioner-toolkit/1-claude-code.md)
  timestamp: 2026-02-05
  pattern_observed: |
    Documenting memory persistence features requires explaining automatic vs manual mechanisms,
    showing hierarchy across memory tiers, and providing decision frameworks for selecting
    appropriate mechanism. The Memory Management section (310 lines) demonstrates:

    **Structure for memory system documentation:**
    1. Opening mental model: Bold assertion bridging concepts ("Session memory bridges ephemeral context and persistent knowledge")
    2. Automatic mechanism explanation: How It Works → Observable Behavior → Feature Gate Status
    3. Manual mechanisms: Commands (/remember, /compact, # shortcut) with workflows
    4. Modular system: Directory structure → Path-scoped rules → Conditional loading → Symlinks
    5. Complete hierarchy table: 7 tiers with Tier/Location/Scope/Automatic/Example Use columns
    6. Feature comparison table: 5 mechanisms × 5 dimensions (Automatic/Persistent/Modular/Path-Scoped/Control)
    7. Decision framework: ASCII tree with binary branching (automatic vs manual → path-specific vs shared)
    8. Practical examples: 3+ copy-paste examples showing real usage
    9. Bidirectional cross-reference: Link to context fundamentals with relationship explanation

    **Key structural decisions:**
    - Automatic mechanisms first (session memory), then manual (.claude/rules/)
    - Each mechanism gets: How It Works → Observable Behavior → Examples
    - Tables for comparison (hierarchy table, feature comparison, enables fast scanning)
    - ASCII decision tree guides readers to appropriate mechanism
    - Bidirectional linking: Memory Management → Context Fundamentals, Context Fundamentals → Memory Management
    - Inline timestamp addition to context fundamentals (*[2026-02-05]*: Claude Code's session memory feature...)

    **Bidirectional linking pattern refinement:**
    - Added cross-reference in claude-code.md Connections section (line 33)
    - Added inline timestamp entry in context-fundamentals.md (lines 26-27)
    - Both links explain the relationship (session memory addresses context vs memory distinction)
    - Enables discovery from either direction
    - Pattern: Major feature docs add Connections entry; related fundamentals get inline timestamp

  evidence: |
    chapters/9-practitioner-toolkit/1-claude-code.md lines 1138-1448 (310 lines)
    - 9 subsections: Mental Model, Session Memory, /remember, /compact, # shortcut, .claude/rules/,
      Hierarchy, Comparison, Decision Framework, Examples, Open Questions
    - 3 tables: Complete Memory Hierarchy (7 tiers), Feature Comparison (5×5), Decision Framework (ASCII tree)
    - Bidirectional cross-reference: claude-code.md ↔ context-fundamentals.md
    - Tags updated: Added session-memory, memory-management, persistent-memory, rules, path-scoping

    chapters/4-context/1-context-fundamentals.md lines 26-27 (2 lines added)
    - Inline timestamped addition linking to Memory Management section
    - Explains how session memory addresses the context vs memory distinction

  when_to_use:
    - Documenting features with automatic AND manual variants
    - Explaining memory/persistence systems with multiple mechanisms
    - Showing hierarchical systems (7-tier memory hierarchy)
    - Providing decision guidance across multiple options

  key_techniques:
    - Mental model opens with bridging assertion (ephemeral → persistent)
    - Automatic mechanisms first (session memory), manual second (.claude/rules/)
    - Tables for quick scanning (hierarchy table, feature comparison)
    - ASCII decision trees guide mechanism selection
    - Practical examples use copy-paste code blocks
    - Bidirectional cross-references with relationship explanation
    - Feature gate warnings upfront (availability callouts)

  trade_offs:
    - advantage: Comprehensive coverage enables readers to select appropriate mechanism
      cost: 310 lines requires strong navigation structure (9 subsections)
    - advantage: Decision framework reduces cognitive load for mechanism selection
      cost: ASCII tree must stay synchronized with actual mechanism capabilities
    - advantage: Bidirectional linking improves discoverability
      cost: Requires coordinated updates across multiple files

stability:
  oscillation_detection:
    rule: |
      IF entry E1 at T1 contradicts E0 at T0
      AND entry E2 at T2 contradicts E1
      THEN oscillation detected
    resolution: |
      Preserve both with conflict marker
      Escalate to human
    detected_oscillations: []

  convergence_indicators:
    insight_rate_trend: "Increasing - two patterns extracted from major documentation efforts"
    new_entries_this_cycle: 2  # agent_teams_documentation + memory_management_documentation
    contradiction_count: 0
    last_reviewed: 2026-02-05
    notes: |
      **Cycle activities:**
      - Analyzed major multi-file documentation update (agent teams, 420 lines)
      - Analyzed memory management documentation (session memory + .claude/rules/, 310 lines)
      - Extracted phased execution pattern from coordinated 6+ file updates
      - Extracted bidirectional linking pattern refinement (Connections + inline timestamp)

      **New patterns added:**
      1. Large Multi-File Feature Documentation (agent_teams_documentation, ~95 lines)
         - Phased execution approach prevents broken references
         - Foundation-first + cascade pattern for terminology consistency
      2. Memory Management Feature Documentation (memory_management_documentation, ~75 lines)
         - Automatic vs manual mechanism documentation structure
         - Bidirectional cross-reference pattern (Connections entry + inline timestamp)
         - Decision framework for mechanism selection (ASCII tree)
         - Hierarchy table pattern (7 tiers with 5 dimensions)

      **Size governance:** 872 lines → 947 lines (+75 lines for memory pattern)
      - Status: APPROACHING WARNING (947 lines, warning at 900)
      - Headroom: -47 lines (already past warning threshold)
      - Action: Consider pruning lower-value tactical entries in next improve cycle
      - Target: Return to ~850 lines (100 line buffer to warning)

      **Contradiction rate:** Zero. Both patterns complement existing guidance.

      **Utility ratio:** High - both patterns applied in substantial production content (420 + 310 = 730 lines).
